# Shri CUT&RUN pipeline

import pandas as pd

sample_csv = pd.read_csv('sample_sheet.csv', index_col='name')
CONDITIONS = set(sample_csv['condition'].tolist())
REPS = set(sample_csv['replicate'].tolist())

# Rule: Main rule to run all other rules
rule all:
    input:
        expand('results/{condition}_{rep}_fastqc.html', condition=CONDITIONS, rep=REPS),
        expand('results/fastqc/{condition}_{rep}.trimmed_fastqc.html', condition=CONDITIONS, rep=REPS),
        expand('results/{condition}_{rep}.trimmed.fastq.gz', condition=CONDITIONS, rep=REPS),
        expand('results/aligned_{condition}.bam', condition=CONDITIONS),
        expand('results/{condition}_filtered.bam', condition=CONDITIONS),
        expand('results/{condition}_dedup.bam', condition=CONDITIONS),
        expand('results/{condition}.sorted.bam', condition=CONDITIONS),
        expand('results/{condition}_dedup.sorted.bam', condition=CONDITIONS),
        expand('results/{condition}.bed', condition=CONDITIONS),
        expand('results/{condition}_peaks_filtered.bed', condition=CONDITIONS),
        #expand('results/{condition}.bigwig', condition=CONDITIONS),
        expand('results/{condition}.bw', condition=CONDITIONS),
        expand('results/{condition}_annotated.bed', condition=CONDITIONS),
        expand('results/motifs/{condition}/', condition=CONDITIONS),
        'results/multiqc_report.html'  

rule fastqc:
    input:
        'samples/{condition}_{rep}.fastq.gz'
    output:
        'results/{condition}_{rep}_fastqc.html'
    threads: 16
    conda:
        'envs/fastqc_env.yml'
    shell:
        'fastqc -t {threads} -o results/ {input}'

rule trimmomatic_pe:
    input:
        R1='samples/{condition}_R1.fastq.gz',
        R2='samples/{condition}_R2.fastq.gz'
    output:
        R1='results/{condition}_R1.trimmed.fastq.gz',
        R2='results/{condition}_R2.trimmed.fastq.gz',
        R1_unpaired='results/{condition}_R1.unpaired.fastq.gz',
        R2_unpaired='results/{condition}_R2.unpaired.fastq.gz'
    params:
        adapters='TruSeq3-PE-2.fa' 
    threads: 16
    conda:
        'envs/trimmomatic_env.yml'
    shell:
        '''
        trimmomatic PE -threads {threads} \
            -phred33 \
            {input.R1} {input.R2} \
            {output.R1} {output.R1_unpaired} \
            {output.R2} {output.R2_unpaired} \
            ILLUMINACLIP:{params.adapters}:2:30:10 \
            LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36
        '''

rule fastqc_trim:
    input:
        'results/{condition}_{rep}.trimmed.fastq.gz'
    output:
        'results/fastqc/{condition}_{rep}.trimmed_fastqc.html'
    threads: 16
    conda:
        'envs/fastqc_env.yml'
    shell:
        'fastqc -t {threads} -o results/fastqc/ {input}'

rule bowtie2_align:
    input:
        R1='results/{condition}_R1.trimmed.fastq.gz',
        R2='results/{condition}_R2.trimmed.fastq.gz'
    output:
        'results/aligned_{condition}.bam'
    threads: 16
    params:
        index='/projectnb/langchip/PersonalFolder/Shri/atacseq/results/genome_index_full'
    conda:
        'envs/bowtie2_env.yml'
    shell:
        '''
        bowtie2 -x {params.index} -p {threads} -1 {input.R1} -2 {input.R2} | samtools view -bS - > {output}
        '''

rule filter_mapq:
    input:
        'results/aligned_{condition}.bam'
    output:
        'results/{condition}_filtered.bam'
    threads: 16
    conda:
        'envs/samtools_env.yml'
    shell:
        '''
        samtools view -b -q 30 {input} > {output}
        '''

rule samtools_sort:
    input:
        'results/{condition}_filtered.bam'
    output:
        bam_sorted='results/{condition}.sorted.bam',
        bam_sorted_index='results/{condition}.sorted.bam.bai'
    conda:
        'envs/samtools_env.yml'
    shell:
        '''
        samtools sort -@ {threads} -o {output.bam_sorted} {input}
        samtools index {output.bam_sorted}
        '''

rule remove_duplicates:
    input:
        'results/{condition}.sorted.bam'
    output:
        'results/{condition}_dedup.bam'
    params:
        metrics='results/{condition}_dedup_metrics.txt'
    threads: 16
    conda:
        'envs/picard_env.yml'
    shell:
        '''
        picard MarkDuplicates INPUT={input} OUTPUT={output} METRICS_FILE={params.metrics} REMOVE_DUPLICATES=true
        '''

rule samtools_sort_dedup:
    input:
        'results/{condition}_dedup.bam'
    output:
        bam_sorted='results/{condition}_dedup.sorted.bam',
        bam_sorted_index='results/{condition}_dedup.sorted.bam.bai'
    conda:
        'envs/samtools_env.yml'
    shell:
        '''
        samtools sort -@ {threads} -o {output.bam_sorted} {input}
        samtools index {output.bam_sorted}
        '''

rule bamCoverage:
    input: 
        bam = 'results/{condition}_dedup.sorted.bam',
        index = 'results/{condition}_dedup.sorted.bam.bai'
    output: 
        'results/{condition}.bw'
    threads: 16
    conda: 
        'envs/deeptools_env.yml'
    shell: 
        '''
        bamCoverage -b {input.bam} -o {output}
        '''

rule bam_to_bed:
    input:
        'results/{condition}_dedup.bam',
    output:
        'results/{condition}.bed'
    threads: 16
    conda:
        'envs/bedtools_env.yml'
    shell:
        '''
        bedtools bamtobed -i {input} > {output}
        '''

rule call_peaks:
    input:
        bed='results/{condition}.bed'
    output:
        peaks='results/{condition}_summits.bed'
    params:
        outdir='results'
    shell: 
        '''
        macs2 callpeak -t {input.bed} -f BED -n {wildcards.condition} --outdir {params.outdir} -g hs --qvalue 0.05 --nomodel
        '''

rule filter_blacklist:
    input:
        peaks = 'results/{condition}_summits.bed',
        blacklist = 'hg19-blacklist.v2.bed'
    output: 
        'results/{condition}_peaks_filtered.bed'
    conda: 
        'envs/bedtools_env.yml'
    shell: 
        '''
        bedtools intersect -a {input.peaks} -b {input.blacklist} -v > {output}
        '''

rule bedgraph:
    input:
        'results/{condition}_peaks_filtered.bed'
    output:
        'results/{condition}_peaks.bedgraph'
    params:
        genome_size='hg19.chrom.sizes.txt'
    conda:
        'envs/bedtools_env.yml'
    shell:
        '''
        bedtools genomecov -i {input} -bg -g {params.genome_size} > {output}
        '''

rule bedgraph_to_bigwig:
    input:
        bedgraph='results/{condition}_peaks.bedgraph'
    output:
        bigwig='results/{condition}.bigwig'
    params:
        genome_size='hg19.chrom.sizes.txt'
    conda:
        'envs/ucsc_tools.yml'  
    shell:
        '''
        bedGraphToBigWig {input.bedgraph} {params.genome_size} {output.bigwig}
        '''

rule annotate_peaks:
    input:
        filtered = 'results/{condition}_peaks_filtered.bed',
        annotation = '/projectnb/langchip/PersonalFolder/Shri/atacseq/results/hg19_annotation.gtf'
    output: 
        'results/{condition}_annotated.bed'
    conda: 
        'envs/homer_env.yml'
    shell: 
        '''
        annotatePeaks.pl {input.filtered} hg19 -gtf {input.annotation} > {output}
        '''

rule motifs:
    input:
        peaks = 'results/{condition}_annotated.bed',
        genome = '/projectnb/langchip/PersonalFolder/Shri/atacseq/results/hg19.fa'
    output: 
        directory('results/motifs/{condition}/')
    conda: 
        'envs/homer_env.yml'
    shell: 
        '''
        findMotifsGenome.pl {input.peaks} {input.genome} {output} -size 200
        '''

rule samtools_flagstats:
    input:
        'results/{condition}_dedup.bam'
    output:
        'results/{condition}.flagstat.txt'
    conda:
        'envs/samtools_env.yml'
    shell:
        'samtools flagstat {input} > {output}'

rule multiqc:
    input:
        expand('results/{condition}.flagstat.txt', condition=CONDITIONS, rep=REPS)
    output:
        'results/multiqc_report.html'
    conda:
        'envs/multiqc_env.yml'
    shell:
        'multiqc results/ -o . -n results/multiqc_report.html'
